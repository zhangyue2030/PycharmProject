from lxml import etreeimport  requestsimport  jsonclass QuibaiSpider:    def __init__(self):        self.url_temp = "https://www.qiushibaike.com/8hr/page/{}/"        self.headers = { "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.75 Safari/537.36"}    def get_url_list(self):        url_list = [self.url_temp.format(i) for i in range(1,14)]        return  url_list    def parse_url(self,url):        response = requests.get(url,headers=self.headers)        return response.content.decode()    def get_content_list(self,html_str):        html = etree.HTML(html_str)        div_list = html.xpath("//div[@id='content-left']/div")        content_list = []        for div in div_list:            item = {}            item["author_name"] = div.xpath(".//h2/text()")[0].strip() if len(div.xpath(".//h2/text()"))>0 else None            item["content"] ={ i.replace("\n","")  for i in div.xpath(".//div[@class='content']/span/text()")}            item["stats_vote"] = div.xpath(".//span[@class='stats-vote']/i/text()")            item["stats_vote"] = item["stats_vote"][0] if len(item["stats_vote"])>0 else None            item["stats_comment"] = div.xpath(".//span[@class='stats-comments']//i/text()")            item["stats_comment"] = item["stats_comment"][0] if len(item["stats_comment"]) > 0 else None            item["img"] = div.xpath(".//div[@class='thumb']//img/@src")            item["img"] = "https:" + item["img"][0] if len(item["img"]) > 0 else None            #注意此处，如果img有值，则会与前面https相连接，如果没有值，直接赋给前面，none与https是不可能有机会相加的            content_list.append(item)        return content_list    def save_content_list(self,content_list):        with open("../../ResultFiles/qiubai.txt","a",encoding="utf-8") as f:            for content in content_list:                f.write(json.dumps(content,ensure_ascii=False))                f.write("\n")        print("保存成功")    '''    实现主要逻辑    '''    def run(self):        #1.根据url规律，构造url        url_list = self.get_url_list()        #2.发送请求，获取相应        for url in url_list:            html_str = self.parse_url(url)        #3.提取数据            content_list = self.get_content_list(html_str)        #4.保存            self.save_content_list(content_list)if __name__ =="__main__":    qiubai = QuibaiSpider()    qiubai.run()